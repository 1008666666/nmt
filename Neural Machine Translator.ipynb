{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://github.com/spro/practical-pytorch\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "from mosestokenizer import *\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 30\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {\"UNK\": 0}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"UNK\"}\n",
    "        self.n_words = 3  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence, topnwords):\n",
    "        for word in sentence:\n",
    "            if word in topnwords:\n",
    "                self.addWord(word)\n",
    "            else:\n",
    "                self.word2count[\"UNK\"] += 1\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "def readLangs(datasets, lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    pairs = []\n",
    "    tokened_pairs = []\n",
    "    tokenizer1 = MosesTokenizer(lang1)\n",
    "    tokenizer2 = MosesTokenizer(lang2)\n",
    "    cnt = 0\n",
    "    for dataset in datasets:\n",
    "        # Read the file and split into lines\n",
    "        lines1 = open('dataset/' + dataset + '/' + dataset + '.' + lang1, encoding='utf-8').read().strip().split('\\n')\n",
    "        lines2 = open('dataset/' + dataset + '/' + dataset + '.' + lang2, encoding='utf-8').read().strip().split('\\n')\n",
    "\n",
    "        # Split every line into pairs and normalize\n",
    "        for line1, line2 in zip(lines1, lines2):\n",
    "            pair1 = tokenizer1(line1)\n",
    "            pair2 = tokenizer2(line2)\n",
    "            if (len(pair1) < MAX_LENGTH) and (len(pair2) < MAX_LENGTH):\n",
    "                pairs.append([line1, line2])            \n",
    "                tokened_pairs.append([pair1, pair2])                \n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs, tokened_pairs\n",
    "\n",
    "def topnwords(pairs, lang, n):\n",
    "        # Read the file and split into lines\n",
    "    lang_list = [word for pair in pairs for word in pair[lang]]          \n",
    "    top_n = Counter(lang_list).most_common(n)\n",
    "    \n",
    "    return [i[0] for i in top_n]\n",
    "\n",
    "def prepareData(datasets, lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs, tokened_pairs = readLangs(datasets, lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    input_lang.topnwords = topnwords(tokened_pairs, 0, 30000)\n",
    "    output_lang.topnwords = topnwords(tokened_pairs, 1, 30000)\n",
    "    print(\"Counting words...\")\n",
    "    for pair in tokened_pairs:\n",
    "        input_lang.addSentence(pair[0], input_lang.topnwords)\n",
    "        output_lang.addSentence(pair[1], output_lang.topnwords)\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs, tokened_pairs\n",
    "    \n",
    "def indexesFromSentence(lang, sentence):   \n",
    "    var = [lang.word2index[word] if word in lang.topnwords else 2 for word in sentence ]\n",
    "    var.append(EOS_token)\n",
    "    return var\n",
    "\n",
    "def variablesFromPairs(pairs):\n",
    "    variables = []\n",
    "    for i, pair in enumerate(pairs):\n",
    "        var_pair = [indexesFromSentence(input_lang, pair[0]), indexesFromSentence(output_lang, pair[1])]\n",
    "        variables.append(var_pair)          \n",
    "    return variables\n",
    "    \n",
    "# datasets = ['commoncrawl', 'europarl', 'un']\n",
    "datasets = ['europarl']\n",
    "\n",
    "# input_lang, output_lang, pairs, tokened_pairs = prepareData(datasets, 'en', 'fr', True)\n",
    "# with open('pairs_30.pkl', 'wb') as file:\n",
    "#     pickle.dump((input_lang, output_lang, pairs, tokened_pairs), file, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "# with open('pairs_30.pkl', 'rb') as file:\n",
    "#     input_lang, output_lang, pairs, tokened_pairs = pickle.load(file)\n",
    "    \n",
    "# variables = variablesFromPairs(tokened_pairs)\n",
    "#     with open('pairs_30_var.pkl', 'wb') as file:\n",
    "#         pickle.dump((input_lang, output_lang, variables), file, protocol = pickle.HIGHEST_PROTOCOL)   \n",
    "# with open('pairs_30_var.pkl', 'rb') as file:\n",
    "#    input_lang, output_lang, variables = pickle.load(file)\n",
    "\n",
    "# print(random.choice(pairs))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, batch_size, mini_batch_size, is_training):\n",
    "        self.batch_size = batch_size\n",
    "        self.minibatch_size = mini_batch_size\n",
    "        self.token_stream = []\n",
    "        self.is_training = is_training\n",
    "        self.create_batches()\n",
    "\n",
    "    def create_batches(self):\n",
    "        input_lang, output_lang, pairs = pickle.load(open('pairs_30_var.pkl', 'rb'))\n",
    "        self.input_lang = input_lang\n",
    "        self.output_lang = output_lang\n",
    "        self.pairs = np.array(pairs)\n",
    "        self.data_num = len(pairs)\n",
    "        indices = np.arange(self.data_num)\n",
    "        np.random.shuffle(indices)\n",
    "        self.indices = indices\n",
    "        self.num_batch = int(self.data_num / self.batch_size)\n",
    "        self.num_minibatch = int(self.batch_size / self.minibatch_size)\n",
    "        self.batch_pointer = 0\n",
    "        self.minibatch_pointer = 0\n",
    "        \n",
    "    def next_batch(self):\n",
    "        self.batch_pointer = (self.batch_pointer + 1) % self.num_batch\n",
    "        start_pos = self.batch_pointer * self.batch_size\n",
    "        idx = self.indices[start_pos:(start_pos+self.batch_size)]\n",
    "        self.batch = np.array(sorted(self.pairs[idx], key = lambda pair: len(pair[0])))\n",
    "        \n",
    "    def next_minibatch(self):\n",
    "        self.minibatch_pointer = (self.minibatch_pointer + 1) % self.num_minibatch\n",
    "        start_pos = self.minibatch_pointer * self.minibatch_size\n",
    "        input_sentences = self.batch[start_pos:(start_pos+self.minibatch_size), 0]\n",
    "        target_sentences = self.batch[start_pos:(start_pos+self.minibatch_size), 1]\n",
    "        return input_sentences, target_sentences\n",
    "    \n",
    "    def reset_pointer(self):\n",
    "        self.batch_pointer = 0\n",
    "        self.minibatch_pointer = 0\n",
    "        np.random.shuffle(self.indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embed_size, embedding):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "        self.embedding = embedding\n",
    "        self.gru = nn.GRU(self.embed_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).unsqueeze(0)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/pytorch/pytorch/issues/805 erogol\n",
    "class Maxout(nn.Module):\n",
    "    def __init__(self, d_in, d_out, pool_size):\n",
    "        super().__init__()\n",
    "        self.d_in, self.d_out, self.pool_size = d_in, d_out, pool_size\n",
    "        self.lin = nn.Linear(d_in, d_out * pool_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        shape = list(inputs.size())\n",
    "        shape[-1] = self.d_out\n",
    "        shape.append(self.pool_size)\n",
    "        max_dim = len(shape) - 1\n",
    "        out = self.lin(inputs)\n",
    "        m, i = out.view(*shape).max(max_dim)\n",
    "        return m    \n",
    "\n",
    "# https://github.com/keon/seq2seq/blob/master/model.py\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attn = nn.Linear(self.hidden_size * 3, hidden_size)\n",
    "        self.v = nn.Parameter(torch.rand(hidden_size))\n",
    "        stdv = 1. / math.sqrt(self.v.size(0))\n",
    "        self.v.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        timestep = encoder_outputs.size(0)\n",
    "        h = hidden.repeat(timestep, 1, 1).transpose(0, 1)\n",
    "        encoder_outputs = encoder_outputs.transpose(0, 1)  # [B*T*H]\n",
    "        attn_energies = self.score(h, encoder_outputs)\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1)\n",
    "\n",
    "    def score(self, hidden, encoder_outputs):\n",
    "        # [B*T*2H]->[B*T*H]\n",
    "        energy = torch.tanh(self.attn(torch.cat([hidden, encoder_outputs], 2)))\n",
    "        energy = energy.transpose(1, 2)  # [B*H*T]\n",
    "        v = self.v.repeat(encoder_outputs.size(0), 1).unsqueeze(1)  # [B*1*H]\n",
    "        energy = torch.bmm(v, energy)  # [B*1*T]\n",
    "        return energy.squeeze(1)  # [B*T]\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embed_size, maxout_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.maxout_size = maxout_size\n",
    "        \n",
    "        self.embed = nn.Embedding(output_size, embed_size)\n",
    "        self.attention = Attention(hidden_size)\n",
    "        self.maxout = nn.Linear(hidden_size * 3 + embed_size, maxout_size * 2)\n",
    "        self.gru = nn.GRU(hidden_size * 2 + embed_size , hidden_size)\n",
    "        self.maxout = Maxout(hidden_size * 3 + embed_size, maxout_size, 2)\n",
    "        self.out = nn.Linear(maxout_size, output_size)\n",
    "        \n",
    "    def forward(self, input, last_hidden, encoder_outputs):\n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        encoder_outputs = encoder_outputs.transpose(0, 1) \n",
    "        embedded = self.embed(input)  # 1 B m\n",
    "        # Calculate attention weights and apply to encoder outputs\n",
    "        attn_weights = self.attention(last_hidden[-1], encoder_outputs) # t\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))  # (B,1,N)\n",
    "        context = context.transpose(0, 1)  # (1,B,N)\n",
    "        rnn_input = torch.cat([embedded, context], 2)\n",
    "        out, hidden = self.gru(rnn_input, last_hidden)\n",
    "        maxout_input = torch.cat([last_hidden, embedded, context], 2)\n",
    "        output = self.maxout(maxout_input).squeeze(0)    \n",
    "        output = self.out(output)\n",
    "        output = F.log_softmax(output, dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_variables, target_variables, encoder1, encoder2, decoder, encoder1_optimizer, encoder2_optimizer, decoder_optimizer, transition, criterion, max_length=MAX_LENGTH):\n",
    "    encoder1_optimizer.zero_grad()\n",
    "    encoder2_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    minibatch_size = len(input_variables)\n",
    "    input_maxlength = len(max(input_variables, key = lambda inp: len(inp)))\n",
    "    target_maxlength = len(max(target_variables, key = lambda tar: len(tar)))\n",
    "    \n",
    "    \n",
    "    for i in range(minibatch_size):\n",
    "        n = input_maxlength - len(input_variables[i])\n",
    "        if n != 0:\n",
    "            input_variables[i].extend([0] * n) \n",
    "        m = target_maxlength - len(target_variables[i])\n",
    "        if m != 0:\n",
    "            target_variables[i].extend([0] * m) \n",
    "            \n",
    "    input_variables = np.array(list(input_variables))\n",
    "    target_variables = np.array(list(target_variables))\n",
    "    input_variables = Variable(torch.LongTensor(input_variables))\n",
    "    input_variables = input_variables.cuda() if use_cuda else input_variables\n",
    "    target_variables = Variable(torch.LongTensor(target_variables))\n",
    "    target_variables = target_variables.cuda() if use_cuda else target_variables\n",
    "        \n",
    "    encoder1_hidden = Variable(torch.zeros(1, minibatch_size, encoder1.hidden_size))\n",
    "    encoder1_hidden = encoder1_hidden.cuda() if use_cuda else encoder1_hidden\n",
    "    encoder2_hidden = Variable(torch.zeros(1, minibatch_size, encoder2.hidden_size))\n",
    "    encoder2_hidden = encoder2_hidden.cuda() if use_cuda else encoder2_hidden\n",
    "    \n",
    "    encoder_outputs = Variable(torch.zeros(minibatch_size, max_length, encoder1.hidden_size * 2))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "    \n",
    "    loss = 0\n",
    "    for ei in range(input_maxlength):\n",
    "        encoder_output, encoder1_hidden = encoder1(\n",
    "            input_variables[:, ei], encoder1_hidden)\n",
    "        encoder_outputs[:, ei, :encoder1.hidden_size] = encoder_output\n",
    "    for ei in reversed(range(input_maxlength)):\n",
    "        encoder_output, encoder2_hidden = encoder2(\n",
    "            input_variables[:, ei], encoder2_hidden)\n",
    "        encoder_outputs[:, ei, encoder2.hidden_size:] = encoder_output\n",
    "        \n",
    "    Ws_input = encoder_output\n",
    "    decoder_hidden = torch.tanh(transition(Ws_input))     \n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]*minibatch_size]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "        \n",
    "    for di in range(target_maxlength):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs)\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        decoder_input = Variable(topi.transpose(0, 1))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "        loss += criterion(decoder_output, target_variables[:, di])\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder1_optimizer.step()\n",
    "    encoder2_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / (target_maxlength * minibatch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))  \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch = 1600\n",
    "mini_batch = 80\n",
    "learning_rate=1\n",
    "rho= 0.95\n",
    "eps = 1e-06\n",
    "weight_decay = 1e-03\n",
    "     \n",
    "def trainIters(encoder1, encoder2, decoder, transition, epoch=1, print_every=10, plot_every=50):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder1_optimizer = optim.Adadelta(encoder1.parameters(), lr=learning_rate, rho=rho, eps=eps, weight_decay=weight_decay)\n",
    "    encoder2_optimizer = optim.Adadelta(encoder2.parameters(), lr=learning_rate, rho=rho, eps=eps, weight_decay=weight_decay)\n",
    "    decoder_optimizer = optim.Adadelta(decoder.parameters(), lr=learning_rate, rho=rho, eps=eps, weight_decay=weight_decay)\n",
    "    \n",
    "    dataloader = DataLoader(batch, mini_batch, is_training=True)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for ep in range(1, epoch + 1):\n",
    "        dataloader.reset_pointer()\n",
    "        for bt in range(1, dataloader.batch_size+1):\n",
    "            dataloader.next_batch()\n",
    "            for mt in range(dataloader.minibatch_size):\n",
    "                input_variables, target_variables = dataloader.next_minibatch()\n",
    "                loss = train(input_variables, target_variables, encoder1, encoder2,\n",
    "                             decoder, encoder1_optimizer, encoder2_optimizer, decoder_optimizer, transition, criterion)\n",
    "                print_loss_total += loss\n",
    "                plot_loss_total += loss\n",
    "\n",
    "            if bt % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                print('%s (%d %d%%) %.4f' % (timeSince(start, bt / batch), bt, bt / batch * 100, print_loss_avg))\n",
    "\n",
    "            if bt % plot_every == 0:\n",
    "                torch.save(encoder1, 'encoder1.pt')\n",
    "                torch.save(encoder2, 'encoder2.pt')\n",
    "                torch.save(decoder, 'decoder.pt')\n",
    "                torch.save(transition, 'transition.pt')\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "                showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 2s (- 1658m 57s) (1 0%) 3.4472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sungwonlyu/anaconda3/envs/py36/lib/python3.6/site-packages/torch/serialization.py:158: UserWarning: Couldn't retrieve source code for container of type EncoderRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/sungwonlyu/anaconda3/envs/py36/lib/python3.6/site-packages/torch/serialization.py:158: UserWarning: Couldn't retrieve source code for container of type DecoderRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/sungwonlyu/anaconda3/envs/py36/lib/python3.6/site-packages/torch/serialization.py:158: UserWarning: Couldn't retrieve source code for container of type Attention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/sungwonlyu/anaconda3/envs/py36/lib/python3.6/site-packages/torch/serialization.py:158: UserWarning: Couldn't retrieve source code for container of type Maxout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 58s (- 1574m 14s) (2 0%) 3.2220\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 1000\n",
    "embed_size = 620\n",
    "maxout_size = 500\n",
    "\n",
    "# lang1_embedding = nn.Embedding(input_lang.n_words, embed_size)\n",
    "# encoder1 = EncoderRNN(hidden_size, embed_size, lang1_embedding)\n",
    "# encoder2 = EncoderRNN(hidden_size, embed_size, lang1_embedding)\n",
    "# decoder = DecoderRNN(hidden_size, embed_size, maxout_size, output_lang.n_words)\n",
    "# transition = nn.Linear(encoder1.hidden_size, encoder1.hidden_size)\n",
    "encoder1 = torch.load('encoder1.pt')\n",
    "encoder2 = torch.load('encoder2.pt')\n",
    "decoder = torch.load('decoder.pt')\n",
    "transition = torch.load('transition.pt')\n",
    "\n",
    "if use_cuda:\n",
    "    encoder1 = encoder1.cuda()\n",
    "    encoder2 = encoder2.cuda()    \n",
    "    decoder = decoder.cuda()\n",
    "    transition = transition.cuda()\n",
    "\n",
    "trainIters(encoder1, encoder2, decoder, transition, 1, print_every=1, plot_every = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder1, encoder2,decoder, transition, sentence, max_length=MAX_LENGTH):\n",
    "    \n",
    "    input_variable = indexesFromSentence(input_lang, sentence)\n",
    "    input_variable = Variable(torch.LongTensor(input_variable))\n",
    "    input_variable = input_variable.cuda() if use_cuda else input_variable\n",
    "    input_length = input_variable.size()[0]\n",
    "    \n",
    "    encoder1_hidden = Variable(torch.zeros(1, 1, encoder1.hidden_size))\n",
    "    encoder1_hidden = encoder1_hidden.cuda() if use_cuda else encoder1_hidden\n",
    "    encoder2_hidden = Variable(torch.zeros(1, 1, encoder2.hidden_size))\n",
    "    encoder2_hidden = encoder2_hidden.cuda() if use_cuda else encoder2_hidden\n",
    "    \n",
    "    encoder_outputs = Variable(torch.zeros(1, max_length, encoder1.hidden_size * 2))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "    \n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder1_hidden = encoder1(input_variable[ei], encoder1_hidden)\n",
    "        encoder_outputs[:, ei, :encoder1.hidden_size] = encoder_output\n",
    "\n",
    "    for ei in reversed(range(input_length)):\n",
    "        encoder_output, encoder2_hidden = encoder2(input_variable[ei], encoder2_hidden)\n",
    "        encoder_outputs[:, ei, encoder2.hidden_size:] = encoder_output\n",
    "        \n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))  # SOS\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    Ws_input = encoder_output\n",
    "    decoder_hidden = torch.tanh(transition(Ws_input)) \n",
    "\n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs)\n",
    "        decoder_attentions[di] = decoder_attention.data\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni])\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "def evaluateRandomly(encoder1, encoder2, decoder, transition, n=10):\n",
    "    input_lang, output_lang, pairs, tokened_pairs = pickle.load(open('pairs_30.pkl', 'rb'))\n",
    "    for i in range(n):\n",
    "        pair = random.choice(tokened_pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder1, encoder2, decoder, transition, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder1 = torch.load('encoder1.pt')\n",
    "encoder2 = torch.load('encoder2.pt')\n",
    "decoder = torch.load('decoder.pt')\n",
    "transition = torch.load('transition.pt')\n",
    "\n",
    "if use_cuda:\n",
    "    encoder1 = encoder1.cuda()\n",
    "    encoder2 = encoder2.cuda()    \n",
    "    decoder = decoder.cuda()\n",
    "    transition = transition.cuda()\n",
    "\n",
    "evaluateRandomly(encoder1, encoder2, decoder, transition, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Attempt for beam search\n",
    "#     decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "#             decoder_input, decoder_hidden, encoder_outputs)    \n",
    "#     topv, topi = decoder_output.data.topk(3)\n",
    "#     decoder_input = Variable(topi)\n",
    "#     decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "#     top_prob = torch.exp(decoder_output)    \n",
    "#     decoder_hidden = decoder_hidden.repeat(3, 1, 1).transpose(0,1)\n",
    "# #     encoder_outputs = encoder_outputs.transpose(0,1)\n",
    "# #     encoder_outputs = encoder_outputs.repeat(3, 1, 1, 1).squeeze(1)\n",
    "# #     print(encoder_outputs.size())\n",
    "#     for di in range(1, max_length):\n",
    "#         print(decoder_input.size(), decoder_hidden.size())\n",
    "#         decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "#             decoder_input, decoder_hidden, encoder_outputs)\n",
    "#         print(decoder_input.size(), decoder_hidden.size())\n",
    "#         top_prob = top_prob * torch.exp(decoder_output).squeeze(0)\n",
    "#         topv, topi = top_prob.data.topk(3)\n",
    "# #         print(decoder_hidden)\n",
    "#         print(topv, topi)\n",
    "\n",
    "# top_prob = Variable(LongTensor([1, 1, 1])).cuda()\n",
    "#     for di in range(max_length):\n",
    "#         decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "#             decoder_input, decoder_hidden, encoder_outputs)\n",
    "#         top_prob = top_prob * decoder_output\n",
    "#         topv, topi = decoder_output.data.topk(3)\n",
    "#         decoder_input = Variable(topi.transpose(0, 1))\n",
    "\n",
    "#         decoder_hidden = \n",
    "\n",
    "#         ni = topi[0][0]\n",
    "\n",
    "#         topv, topi = decoder_output.data.topk(1)\n",
    "#         decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "#         loss += criterion(decoder_output, target_variables[:, di])        \n",
    "        \n",
    "#         if ni == EOS_token:\n",
    "#             decoded_words.append('<EOS>')\n",
    "#             break\n",
    "#         else:\n",
    "#             decoded_words.append(output_lang.index2word[ni])\n",
    "\n",
    "#         decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "#         decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "#     return decoded_words, decoder_attentions[:di + 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
